# Langchain-Model-for-Question-Answering-QA

Large language models (LLMs) face various challenges concerning both the accuracy of their knowledge and the timeliness of information. RAG methods offer potential solutions to common issues encountered by these models, such as hallucination and the limitation of knowledge cutoff.

Broadly speaking, a RAG-based architecture empowers the model by granting access to external knowledge sources that offer supplementary context to the initial input prompt. This augmented prompt is subsequently utilized to invoke the large language model, as illustrated in the following.

![](images/RAGs.png)


### Langchain-Model-for-Question-Answering-QA




#### Here's a simple model outlined here. Execute the app.py file, upload your desired document, pose a question, and receive answers enriched with context from your file.
